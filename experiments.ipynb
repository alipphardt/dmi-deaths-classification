{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS737 Final Project\n",
    "Author: Anthony Lipphardt\n",
    "\n",
    "Date: April 23, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMI</th>\n",
       "      <th>literal text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GASTRIC CARCINOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SMALL CELL CARCINOMA PROSTATE METASTATIC PROST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RESPIRATORY FAILURE METASTATIC ANAL SQUAMOUS C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ASPIRATION PNEUMONIA ALZHEIMER DEMENTIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>PULMONARY EDEMA END STAGE RENAL FAILURE STOPPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DMI                                       literal text\n",
       "0    0                                  GASTRIC CARCINOMA\n",
       "1    0  SMALL CELL CARCINOMA PROSTATE METASTATIC PROST...\n",
       "2    0  RESPIRATORY FAILURE METASTATIC ANAL SQUAMOUS C...\n",
       "3    0            ASPIRATION PNEUMONIA ALZHEIMER DEMENTIA\n",
       "4    0  PULMONARY EDEMA END STAGE RENAL FAILURE STOPPE..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literal_text = pd.read_csv('literal-text.csv', index_col=0)\n",
    "literal_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>literal text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMI</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     literal text\n",
       "DMI              \n",
       "0            2495\n",
       "1            2495"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random undersampling of over represented class and create final balanced dataset\n",
    "\n",
    "undersample = literal_text[literal_text['DMI'] == 0].sample(n=len(literal_text[literal_text['DMI'] == 1]))\n",
    "DMIrows = literal_text[literal_text['DMI'] == 1]\n",
    "\n",
    "final = pd.concat([undersample, DMIrows])\n",
    "final.groupby('DMI').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Optimal Values for LSA\n",
    "Using optimal parameters for CountVectorizer, find values for n_components hyperparameter that retains 85, 90, and 95 percent of explained variance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 3368\n"
     ]
    }
   ],
   "source": [
    "# Convert data using CountVectorizer with optimal parameters and run dimensionality reduction\n",
    "\n",
    "cv = CountVectorizer(lowercase=False, binary=True, min_df=3, ngram_range=(1, 2))\n",
    "tf = cv.fit_transform(final['literal text'])\n",
    "print(\"Number of words:\",len(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850446039784\n",
      "0.902411055327\n",
      "0.950075847035\n"
     ]
    }
   ],
   "source": [
    "# Find values for n_components that find 85%, 90%, and 95% variance\n",
    "\n",
    "for i in (525, 775, 1180):\n",
    "    svd = TruncatedSVD(n_components=i)\n",
    "    svd.fit(tf)\n",
    "    print(np.sum(svd.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Train and Test Data\n",
    "Split final balanced dataset into target and test sets using a 75:25 split. Data and targets will be separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "train, test, traint, testt = train_test_split(final['literal text'], final['DMI'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Pipelines and Parameters for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for Naive Bayes and SVM workflows\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "    ('NBvect', CountVectorizer(lowercase=False,binary=True)),\n",
    "    ('NBclf', BernoulliNB(binarize=None))\n",
    "])\n",
    "\n",
    "SVM1_pipeline = Pipeline([\n",
    "    ('SVMvect', CountVectorizer(lowercase=False,binary=True)),\n",
    "    ('SVMclf', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "SVM2_pipeline = Pipeline([\n",
    "    ('SVMvect', CountVectorizer(lowercase=False,binary=True)),\n",
    "    ('SVMdim', TruncatedSVD()),\n",
    "    ('SVMclf', SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create parameter grids for Naive Bayes and SVM workflows\n",
    "\n",
    "NB_parameters = {\n",
    "    \n",
    "    'NBvect__min_df': (3,5),\n",
    "    'NBvect__ngram_range': ((1,1),(1,2)),\n",
    "    \n",
    "    'NBclf__alpha': (0, 0.1, 0.5, 1)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SVM1_parameters = {\n",
    "    \n",
    "    'SVMvect__min_df': (3,5),\n",
    "    'SVMvect__ngram_range': ((1,1),(1,2)),\n",
    "  \n",
    "    'SVMclf__C': (1, 10, 100, 1000)\n",
    "    \n",
    "}\n",
    "\n",
    "SVM2_parameters = {\n",
    "    \n",
    "    'SVMvect__min_df': (3,),    \n",
    "    'SVMvect__ngram_range': ((1,2),),    \n",
    "\n",
    "    'SVMdim__n_components': (525, 775, 1180),\n",
    "\n",
    "    'SVMclf__C': (1,)\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTests(data, targets, pipeline, parameters):\n",
    "\n",
    "    \"\"\" Perform grid search with specified pipeline and parameters\n",
    "        on data training set with targets as labels\n",
    "        \n",
    "        Evaluate performance based on precision and print parameters\n",
    "        for best estimator\n",
    "        \n",
    "        grid search object is returned for further analysis\"\"\"\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters, verbose=1, cv=10, scoring='precision')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(data, targets)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search for Each Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['NBvect', 'NBclf']\n",
      "parameters:\n",
      "{'NBvect__min_df': (3, 5), 'NBvect__ngram_range': ((1, 1), (1, 2)), 'NBclf__alpha': (0, 0.1, 0.5, 1)}\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonylipphardt/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 30.803s\n",
      "\n",
      "Best score: 0.987\n",
      "Best parameters set:\n",
      "\tNBclf__alpha: 1\n",
      "\tNBvect__min_df: 3\n",
      "\tNBvect__ngram_range: (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:   30.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Run grid search for Naive Bayes\n",
    "NB_grid_search = runTests(train, traint, NB_pipeline, NB_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['SVMvect', 'SVMclf']\n",
      "parameters:\n",
      "{'SVMvect__min_df': (3, 5), 'SVMvect__ngram_range': ((1, 1), (1, 2)), 'SVMclf__C': (1, 10, 100, 1000)}\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 64.498s\n",
      "\n",
      "Best score: 0.994\n",
      "Best parameters set:\n",
      "\tSVMclf__C: 1\n",
      "\tSVMvect__min_df: 3\n",
      "\tSVMvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Run grid search for SVM without dimensionality reduction\n",
    "SVM1_grid_search = runTests(train, traint, SVM1_pipeline, SVM1_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['SVMvect', 'SVMdim', 'SVMclf']\n",
      "parameters:\n",
      "{'SVMvect__min_df': (3,), 'SVMvect__ngram_range': ((1, 2),), 'SVMdim__n_components': (525, 775, 1180), 'SVMclf__C': (1,)}\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 217.647s\n",
      "\n",
      "Best score: 0.994\n",
      "Best parameters set:\n",
      "\tSVMclf__C: 1\n",
      "\tSVMdim__n_components: 1180\n",
      "\tSVMvect__min_df: 3\n",
      "\tSVMvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Run grid search for SVM with dimensionality reduction\n",
    "SVM2_grid_search = runTests(train, traint, SVM2_pipeline, SVM2_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine and Export Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.972749</td>\n",
       "      <td>{'NBclf__alpha': 0, 'NBvect__min_df': 3, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.975476</td>\n",
       "      <td>{'NBclf__alpha': 0, 'NBvect__min_df': 3, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.979112</td>\n",
       "      <td>{'NBclf__alpha': 0, 'NBvect__min_df': 5, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.980173</td>\n",
       "      <td>{'NBclf__alpha': 0, 'NBvect__min_df': 5, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.983301</td>\n",
       "      <td>{'NBclf__alpha': 0.1, 'NBvect__min_df': 3, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>{'NBclf__alpha': 0.1, 'NBvect__min_df': 3, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.983265</td>\n",
       "      <td>{'NBclf__alpha': 0.1, 'NBvect__min_df': 5, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.984323</td>\n",
       "      <td>{'NBclf__alpha': 0.1, 'NBvect__min_df': 5, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.985368</td>\n",
       "      <td>{'NBclf__alpha': 0.5, 'NBvect__min_df': 3, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>{'NBclf__alpha': 0.5, 'NBvect__min_df': 3, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.983755</td>\n",
       "      <td>{'NBclf__alpha': 0.5, 'NBvect__min_df': 5, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.985325</td>\n",
       "      <td>{'NBclf__alpha': 0.5, 'NBvect__min_df': 5, 'NB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.986990</td>\n",
       "      <td>{'NBclf__alpha': 1, 'NBvect__min_df': 3, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.985843</td>\n",
       "      <td>{'NBclf__alpha': 1, 'NBvect__min_df': 3, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>{'NBclf__alpha': 1, 'NBvect__min_df': 5, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.986893</td>\n",
       "      <td>{'NBclf__alpha': 1, 'NBvect__min_df': 5, 'NBve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.992468</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMvect__min_df': 3, 'SVMvec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.993522</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMvect__min_df': 3, 'SVMvec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.989298</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMvect__min_df': 5, 'SVMvec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.991921</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMvect__min_df': 5, 'SVMvec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.990280</td>\n",
       "      <td>{'SVMclf__C': 10, 'SVMvect__min_df': 3, 'SVMve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.992970</td>\n",
       "      <td>{'SVMclf__C': 10, 'SVMvect__min_df': 3, 'SVMve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.985457</td>\n",
       "      <td>{'SVMclf__C': 10, 'SVMvect__min_df': 5, 'SVMve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>{'SVMclf__C': 10, 'SVMvect__min_df': 5, 'SVMve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.989706</td>\n",
       "      <td>{'SVMclf__C': 100, 'SVMvect__min_df': 3, 'SVMv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.992970</td>\n",
       "      <td>{'SVMclf__C': 100, 'SVMvect__min_df': 3, 'SVMv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.982682</td>\n",
       "      <td>{'SVMclf__C': 100, 'SVMvect__min_df': 5, 'SVMv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>{'SVMclf__C': 100, 'SVMvect__min_df': 5, 'SVMv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.989706</td>\n",
       "      <td>{'SVMclf__C': 1000, 'SVMvect__min_df': 3, 'SVM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.992970</td>\n",
       "      <td>{'SVMclf__C': 1000, 'SVMvect__min_df': 3, 'SVM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.982682</td>\n",
       "      <td>{'SVMclf__C': 1000, 'SVMvect__min_df': 5, 'SVM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM w/o Reduction</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>{'SVMclf__C': 1000, 'SVMvect__min_df': 5, 'SVM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM with Reduction</td>\n",
       "      <td>0.991885</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMdim__n_components': 525, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM with Reduction</td>\n",
       "      <td>0.993517</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMdim__n_components': 775, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM with Reduction</td>\n",
       "      <td>0.994044</td>\n",
       "      <td>{'SVMclf__C': 1, 'SVMdim__n_components': 1180,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  mean_test_score  \\\n",
       "0          Naive Bayes         0.972749   \n",
       "1          Naive Bayes         0.975476   \n",
       "2          Naive Bayes         0.979112   \n",
       "3          Naive Bayes         0.980173   \n",
       "4          Naive Bayes         0.983301   \n",
       "5          Naive Bayes         0.984848   \n",
       "6          Naive Bayes         0.983265   \n",
       "7          Naive Bayes         0.984323   \n",
       "8          Naive Bayes         0.985368   \n",
       "9          Naive Bayes         0.985890   \n",
       "10         Naive Bayes         0.983755   \n",
       "11         Naive Bayes         0.985325   \n",
       "12         Naive Bayes         0.986990   \n",
       "13         Naive Bayes         0.985843   \n",
       "14         Naive Bayes         0.985383   \n",
       "15         Naive Bayes         0.986893   \n",
       "16   SVM w/o Reduction         0.992468   \n",
       "17   SVM w/o Reduction         0.993522   \n",
       "18   SVM w/o Reduction         0.989298   \n",
       "19   SVM w/o Reduction         0.991921   \n",
       "20   SVM w/o Reduction         0.990280   \n",
       "21   SVM w/o Reduction         0.992970   \n",
       "22   SVM w/o Reduction         0.985457   \n",
       "23   SVM w/o Reduction         0.990272   \n",
       "24   SVM w/o Reduction         0.989706   \n",
       "25   SVM w/o Reduction         0.992970   \n",
       "26   SVM w/o Reduction         0.982682   \n",
       "27   SVM w/o Reduction         0.990272   \n",
       "28   SVM w/o Reduction         0.989706   \n",
       "29   SVM w/o Reduction         0.992970   \n",
       "30   SVM w/o Reduction         0.982682   \n",
       "31   SVM w/o Reduction         0.990272   \n",
       "32  SVM with Reduction         0.991885   \n",
       "33  SVM with Reduction         0.993517   \n",
       "34  SVM with Reduction         0.994044   \n",
       "\n",
       "                                               params  \n",
       "0   {'NBclf__alpha': 0, 'NBvect__min_df': 3, 'NBve...  \n",
       "1   {'NBclf__alpha': 0, 'NBvect__min_df': 3, 'NBve...  \n",
       "2   {'NBclf__alpha': 0, 'NBvect__min_df': 5, 'NBve...  \n",
       "3   {'NBclf__alpha': 0, 'NBvect__min_df': 5, 'NBve...  \n",
       "4   {'NBclf__alpha': 0.1, 'NBvect__min_df': 3, 'NB...  \n",
       "5   {'NBclf__alpha': 0.1, 'NBvect__min_df': 3, 'NB...  \n",
       "6   {'NBclf__alpha': 0.1, 'NBvect__min_df': 5, 'NB...  \n",
       "7   {'NBclf__alpha': 0.1, 'NBvect__min_df': 5, 'NB...  \n",
       "8   {'NBclf__alpha': 0.5, 'NBvect__min_df': 3, 'NB...  \n",
       "9   {'NBclf__alpha': 0.5, 'NBvect__min_df': 3, 'NB...  \n",
       "10  {'NBclf__alpha': 0.5, 'NBvect__min_df': 5, 'NB...  \n",
       "11  {'NBclf__alpha': 0.5, 'NBvect__min_df': 5, 'NB...  \n",
       "12  {'NBclf__alpha': 1, 'NBvect__min_df': 3, 'NBve...  \n",
       "13  {'NBclf__alpha': 1, 'NBvect__min_df': 3, 'NBve...  \n",
       "14  {'NBclf__alpha': 1, 'NBvect__min_df': 5, 'NBve...  \n",
       "15  {'NBclf__alpha': 1, 'NBvect__min_df': 5, 'NBve...  \n",
       "16  {'SVMclf__C': 1, 'SVMvect__min_df': 3, 'SVMvec...  \n",
       "17  {'SVMclf__C': 1, 'SVMvect__min_df': 3, 'SVMvec...  \n",
       "18  {'SVMclf__C': 1, 'SVMvect__min_df': 5, 'SVMvec...  \n",
       "19  {'SVMclf__C': 1, 'SVMvect__min_df': 5, 'SVMvec...  \n",
       "20  {'SVMclf__C': 10, 'SVMvect__min_df': 3, 'SVMve...  \n",
       "21  {'SVMclf__C': 10, 'SVMvect__min_df': 3, 'SVMve...  \n",
       "22  {'SVMclf__C': 10, 'SVMvect__min_df': 5, 'SVMve...  \n",
       "23  {'SVMclf__C': 10, 'SVMvect__min_df': 5, 'SVMve...  \n",
       "24  {'SVMclf__C': 100, 'SVMvect__min_df': 3, 'SVMv...  \n",
       "25  {'SVMclf__C': 100, 'SVMvect__min_df': 3, 'SVMv...  \n",
       "26  {'SVMclf__C': 100, 'SVMvect__min_df': 5, 'SVMv...  \n",
       "27  {'SVMclf__C': 100, 'SVMvect__min_df': 5, 'SVMv...  \n",
       "28  {'SVMclf__C': 1000, 'SVMvect__min_df': 3, 'SVM...  \n",
       "29  {'SVMclf__C': 1000, 'SVMvect__min_df': 3, 'SVM...  \n",
       "30  {'SVMclf__C': 1000, 'SVMvect__min_df': 5, 'SVM...  \n",
       "31  {'SVMclf__C': 1000, 'SVMvect__min_df': 5, 'SVM...  \n",
       "32  {'SVMclf__C': 1, 'SVMdim__n_components': 525, ...  \n",
       "33  {'SVMclf__C': 1, 'SVMdim__n_components': 775, ...  \n",
       "34  {'SVMclf__C': 1, 'SVMdim__n_components': 1180,...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather results from grid search\n",
    "NB_results = pd.DataFrame({'params': NB_grid_search.cv_results_['params'], 'Classifier': 'Naive Bayes', 'mean_test_score': NB_grid_search.cv_results_['mean_test_score']})\n",
    "SVM1_results = pd.DataFrame({'params': SVM1_grid_search.cv_results_['params'], 'Classifier': 'SVM w/o Reduction', 'mean_test_score': SVM1_grid_search.cv_results_['mean_test_score']}) \n",
    "SVM2_results = pd.DataFrame({'params': SVM2_grid_search.cv_results_['params'], 'Classifier': 'SVM with Reduction', 'mean_test_score': SVM2_grid_search.cv_results_['mean_test_score']})\n",
    "grid_search_results = pd.concat([NB_results, SVM1_results, SVM2_results], ignore_index=True)\n",
    "grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fit time: 0.0987403169274\n",
      "Average score time: 0.0104517951608\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes\")\n",
    "print(\"  Average fit time:\",np.mean(NB_grid_search.cv_results_['mean_fit_time']))\n",
    "print(\"  Average score time:\",np.mean(NB_grid_search.cv_results_['mean_score_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (w/o LSA)\n",
      "  Average fit time: 0.217600390315\n",
      "  Average score time: 0.0190324887633\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine (w/o LSA)\")\n",
    "print(\"  Average fit time:\",np.mean(SVM1_grid_search.cv_results_['mean_fit_time']))\n",
    "print(\"  Average score time:\",np.mean(SVM1_grid_search.cv_results_['mean_score_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (w/ LSA)\n",
      "  Average fit time: 5.67686701616\n",
      "  Average score time: 0.132110969226\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine (w/ LSA)\")\n",
    "print(\"  Average fit time:\",np.mean(SVM2_grid_search.cv_results_['mean_fit_time']))\n",
    "print(\"  Average score time:\",np.mean(SVM2_grid_search.cv_results_['mean_score_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export grid search results to CSV\n",
    "grid_search_results.to_csv(path_or_buf='grid-search-results.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimal Classifier Against Test Data\n",
    "Fit training data to optimal classifier, transform test data, and obtain predictions.\n",
    "\n",
    "Classification report and confusion matrix will be computed. Focus is on scoring for precision and specificity of drug mention with involvement (DMI) death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Non-DMI       0.98      0.99      0.98       621\n",
      "        DMI       0.99      0.98      0.98       627\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1248\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[613   8]\n",
      " [ 15 612]]\n"
     ]
    }
   ],
   "source": [
    "# Fit to target data using optimal parameters in grid search and run on test data\n",
    "cv = CountVectorizer(lowercase=False,binary=True, min_df=3, ngram_range=(1,2))\n",
    "tf = cv.fit_transform(train)\n",
    "\n",
    "svd = TruncatedSVD(n_components=1180)\n",
    "tf_svd = svd.fit_transform(tf)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(tf_svd, traint)\n",
    "\n",
    "predicted = clf.predict(svd.transform(cv.transform(test)))\n",
    "\n",
    "precision = precision_score(testt, predicted, average=None)\n",
    "\n",
    "print(classification_report(testt, predicted, target_names=['Non-DMI','DMI']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(testt, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Misclassified Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORDS MISCLASSIFIED AS DMI\n",
      "====================================\n",
      "\n",
      "APPARENT SUDDEN DEATH DUE DIFLUOROETHANE INHALATION HUFFING DECEASED FOUND DEAD BEDROOM FLOOR MULTIPLE CANS COMPRESSED AIR FOUND NEAR BODY \n",
      "\n",
      "CERVICAL SPINE FRACTURE BLUNT IMPACT HEAD FALLEN HITTING HEAD BATHROOM WALL ACUTE ETHANOL INTOXICATION \n",
      "\n",
      "ASPHYXIA SUFFOCATION PLASTIC BAG INTENTIONALLY PLACED PLASTIC BAG HEAD SECURED KNOT \n",
      "\n",
      "ACUTE RESPIRATORY FAILURE ACUTE CHRONIC AORTIC ILIAC THROMBUS ISCHEMIC FOOT BILATERAL METASTASIS BONE LIVER GENRALIZED WEAKNESS DEHYDRATION SUSPECTED PORTAL VEIN THROMBOSIS METABOLIC ACIDOSIS HYPONATREMIA SYSTEMIC INFLAMMATORY RESPONSE SYNDROME TRANSAMINITIS MODERATE PROTEIN CALORIE MALNUTRITION \n",
      "\n",
      "ANOXIC ENCEPHALOPATHY ACUTE ETHANOL INTOXICATION INGESTION LARGE QUANTITIES ALCOHOL BULLOUS EMPHYSEMA CHRONIC ETHANOLISM \n",
      "\n",
      "SELF INFLICTED HANDGUN GUNSHOT WOUND HEAD DECEDENT TOOK LIFE FIRING MM HANDGUN BULLET HEAD SUICIDE NOTE RECOVERED SUICIDAL IDEATION PRIOR ATTEMPTS REPORTED DEPRESSION ALCOHOLISM \n",
      "\n",
      "ASPHYXIA DUE PLASTIC BAG HEAD FRESHWATER DROWNING FOUND CULVERT PLASTIC BAG HEAD \n",
      "\n",
      "TOXIC ASPHYXIA INHALATION CARBON MONOXIDE ENGINE EXHAUST RAN VEHICLE ENCLOSED GARAGE CHRONIC DRUG ABUSE METHAMPHETAMINE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RECORDS MISCLASSIFIED AS DMI\")\n",
    "print(\"====================================\\n\")\n",
    "for record in test[(predicted == 1) & (testt == 0)]:\n",
    "    print(record,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORDS MISCLASSIFIED AS NON-DMI\n",
      "====================================\n",
      "\n",
      "PULMONARY HEMORRHAGE ANTICOAGULATION COUMADIN THERAPY ATRIAL FIBRILLATION LEUKEMIA CONGESTIVE HEART FAILURE \n",
      "\n",
      "DROWNING DECEDENT DROWN JACUZZI TUB ELEVATED GABAPENTIN BLOOD CONCENTRATION \n",
      "\n",
      "RESPIRATORY ARREST SEPSIS DUE ASPIRATION PNEUMONITIS PNEUMONIA SEVERE CHRONIC OBSTRUCTIVE PULMONARY DISEASE ACUTE CHRONIC HYPOXEMIC HYPERCAPNIC RESPIRATORY FAILURE ENCEPHALOPATHY SECONDARY TOXIC MEDICATIONS HISTORY SEVERE PROTEIN CALORIE MALNUTRITION \n",
      "\n",
      "ANATOMICAL CAUSE DEATH UNKNOWN EXTENT DIPHENHYDRAMINE CONTRIBUTED DEATH SUPRA THERAPEUTIC DIPHENHYDRAMINE LEVEL \n",
      "\n",
      "ACUTE RENAL FAILURE PROBABLY MEDICATION NEPHROTOXICITY DEMENTIA H PYLORI INFECTION \n",
      "\n",
      "ASPHYXIA FRESHWATER DROWING FOLLOWING INJECTED HEROIN DEMTHAMPHETAMINE USAGE DISCOVERED SUBMERGED BATHTUB WITHOUT INFLICTED INJURIES SUBSTANCE ABUSE MANY YEARS \n",
      "\n",
      "MASSIVE HEMORRHAGIC SHOCK AORTOENTERIC FISTULA ESOPHAGEAL ULCER BOTOX INJECTION ESOPHAGUS MEDICAL PROCEDURE HYPERTENSION ESOPHAGEAL SPASM \n",
      "\n",
      "HEMORRHAGIC STROKE ANTICOAGULATED ATRIAL FIBRILLATION MULTIPLE RECENT REMOTE GROUND LEVEL FALLS \n",
      "\n",
      "ANOXIC BRAIN INJURY SMOKING HEROIN RESPIRATORY ARREST SMOKING HEROIN DOWNHILL COURSE COMPLICATIONS SUBSTANCE ABUSE MONTHS ADDICTION WEIGHT LOSS EMPHYSEMA \n",
      "\n",
      "ASPHYXIA DUE EXCLUSION OXYGEN HELIUM FILLED BAG HEAD NECK SECURED PLASTIC BAG HEAD CONNECTED HELIUM TANKS \n",
      "\n",
      "HISTORY ARTERIOVENOUS MALFORMATION INTRACRANIAL HEMORRHAGE HYDROCEPHALUS VENTRICULAR PERITONEAL SHUNT POLYPHARMACY HYPERLIPIDEMIA ASTHMA CARDIOMEGALY NONALCOHOLIC FATTY LIVER DISEASE IDIOPATHIC POLYNEUROPATHY \n",
      "\n",
      "RESPIRATORY FAILURE METASTATIC PANCREATIC CANCER CHEMOTOXICITY PNEUMONIA \n",
      "\n",
      "ACUTE ETHANOL FLUOXETINE INTOXICATION SUBDURAL HEMATOMA SHEAR INJURY BLUNT FORCE INJURY HEAD TOXIC USE DRUGS BLUNT HEAD INJURY OCCURRING UNCERTAIN CIRCUMSTANCES \n",
      "\n",
      "RUPTURED CEREBRAL ARTERY ANEURYSM \n",
      "\n",
      "HYPOGLYCEMIA DIABETES APPARENT OVERDOSE INSULIN CHRONIC OBSTRUCTIVE PULMONARY DISEASE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RECORDS MISCLASSIFIED AS NON-DMI\")\n",
    "print(\"====================================\\n\")\n",
    "for record in test[(predicted == 0) & (testt == 1)]:\n",
    "    print(record,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
